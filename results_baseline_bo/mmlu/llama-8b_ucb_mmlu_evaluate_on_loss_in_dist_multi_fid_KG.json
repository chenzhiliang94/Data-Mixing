{
  "final_info_stored": {
    "command line args": {
      "iterations": 50,
      "num_data": 10000,
      "epochs": "1",
      "trials": "3",
      "evaluation_cuda": 0,
      "eval_tasks": "mmlu",
      "eval_method": "eval_loss",
      "experiments_setting": "ood",
      "time_limit": "1000",
      "lora_rank": "128",
      "model": "llama-8b",
      "acq_function": "ucb",
      "ucb_beta": "20",
      "optimize_method": "mixed",
      "save_name": "llama-8b_ucb_mmlu_evaluate_on_loss_in_ood.json",
      "seed": 3132,
      "limit": "100",
      "run_BO_on": "general",
      "training_batch": 32,
      "evaluation_batch": 32,
      "dkl_feature_dim": 32,
      "dkl_hidden": 64,
      "dkl_freeze_nn": false,
      "local_rank": 0
    },
    "training domain": [
      "commonsense_qa",
      "gsm8k",
      "rowan_hellaswag",
      "sciq",
      "triviaqa",
      "truthfulqa_gen",
      "wikitext",
      "arc_challenge"
    ],
    "evaluation domain": [
      "mmlu"
    ],
    "weight": [
      1.0
    ],
    "random": [
      [
        -1.39,
        -1.39,
        -1.3396138485927378,
        -1.3396138485927378,
        -1.3230101396520995,
        -1.3230101396520995,
        -1.3010978279240988,
        -1.2766374344944211,
        -1.2766374344944211,
        -1.2766374344944211,
        -1.2766374344944211,
        -1.2766374344944211,
        -1.2392208036694576,
        -1.2110154675842142,
        -1.2110154675842142,
        -1.2110154675842142,
        -1.2110154675842142,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.195590847609324,
        -1.1953180384305502,
        -1.1953180384305502,
        -1.1953180384305502,
        -1.1953180384305502,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19,
        -1.19
      ],
      [
        -1.3331966951430712,
        -1.3331966951430712,
        -1.3331966951430712,
        -1.3331966951430712,
        -1.3131766421110922,
        -1.3131766421110922,
        -1.279134398828148,
        -1.279134398828148,
        -1.2445936237954094,
        -1.2321094433840796,
        -1.2321094433840796,
        -1.2321094433840796,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.231446658156266,
        -1.2276496820508873,
        -1.2276496820508873,
        -1.2276496820508873,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2213912855880626,
        -1.2101301660719006,
        -1.2034807858699867,
        -1.2034807858699867,
        -1.1989336303270732
      ],
      [
        -1.3246057710409116,
        -1.3246057710409116,
        -1.3073018091242667,
        -1.287858429624988,
        -1.287858429624988,
        -1.2677245076174497,
        -1.2677245076174497,
        -1.2677245076174497,
        -1.2677245076174497,
        -1.2677245076174497,
        -1.2647686778785925,
        -1.2647686778785925,
        -1.2647686778785925,
        -1.2647686778785925,
        -1.2647686778785925,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.244894373471002,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2292423819777383,
        -1.2286784419829324,
        -1.2286784419829324,
        -1.2286784419829324,
        -1.2286784419829324
      ]
    ]
  },
  "BO_params": {
    "acq_function": "ucb",
    "ucb_beta": 20.0,
    "optimize_method": "mixed"
  }
}